start	end	text
8	3735	Do you want me over here?
3735	7862	Yeah that's perfect.
10500	11500	Nice to meet you, Fred.
11500	12320	Very nice to meet you.
12320	13101	Thank you for being here.
13101	14041	Thanks for having me.
14041	19122	Henrik, can you just start, give us a very short round, how do you and Fred know each other?
19122	24104	So Fred and I have been friends and worked together briefly back in 2006-7.
24104	26944	I was working on a documentary about copyright.
26944	35507	Fred was working at a non-profit called Creative Commons, the licensing system that underpins things like Wikipedia.
35507	36607	And so we were in this
37307	43351	group of people that were very idealistic about the internet, and have stayed friends ever since.
43351	44312	That's perfect.
44312	47013	And you've been hanging around in Copenhagen for a couple of days?
47013	49255	Yeah, I got here a week ago, I guess.
49255	53778	And then I went to Sweden for a bit, but Henrik's given me an incredible tour.
53778	56640	We went mushroom hunting on Friday, and that was amazing.
56640	59222	And then I'm going to... In which forest was that?
59222	59822	Sysvile.
59822	60522	Sysvile, yeah.
60522	61363	Yeah, it was wonderful.
61363	64485	We got lots of chanterelles, but what was the Danish name for them?
64933	65354	Cantareller.
65354	65814	Cantareller, yeah.
65814	66555	They were amazing.
66555	67496	We cooked them that night.
67496	68196	Are they good?
68196	69137	Yeah, they were great.
69137	70278	Ah, okay, perfect.
70278	72660	And do you sleep on Henrik's sofa?
72660	74402	No, he's got an incredible guest room.
74402	77164	It was a lovely, it's been a lovely stay.
77164	79867	Som Fred fortæller her, så er han i København for at besøge mig.
79867	81228	Vi er gamle venner.
81228	83150	Vi har været ude og samlet svampe.
83150	85472	Og han bor i mit gæsteverelse i vores hus.
86120	96504	Enough with the hygge and Denmark, you've worked with artificial intelligence for so many years, first at Kickstarter, then at Y Combinator, we'll get back to that in a minute.
96504	101566	What were you trying to accomplish with AI within your career?
101566	111610	So I took a really interesting class in grad school by somebody named Dan Schiffman, courseware, he's a great teacher, and I think the class he taught was called Nature of Code.
112191	122228	and then programming A to Z, and he showed us how to build a spam filter, which sounds really boring, but it's a really interesting way to analyze large amounts of text.
122446	128331	So the spam filters we have in our Gmail, which means I don't have to look up hundreds of mails that I don't want to see.
128331	128731	Exactly.
128731	140059	It's a powerful mathematical algorithm that goes back to probability theory that can analyze an email really quickly and say, it's more likely than not that this email is spam.
140059	142741	So I learned how to do some of that math.
142741	146444	And a couple of years later, I found myself at Kickstarter.
146444	150047	I was the second employee there, and just trying to make myself useful at a startup.
151568	159970	take on interesting projects, and do everything from look at our analytics, to answer queries from the database, to build a little bit of code.
159970	163991	And I picked up a, in America, they called it nights and weekends project.
163991	165591	I don't know if that's a phrase here.
165591	166352	It's probably.
166352	167572	No, we take the weekends off here.
167572	167752	I know.
167752	168432	It's like probably.
168432	169492	Yeah, we don't know that, yeah.
169492	170733	We have no age comps.
170733	170853	Yes.
172413	175835	Fred studied at the university and wrote code.
175835	187103	He was interested in, among other things, a course he took at the university, how spam filters work, and how to use algorithms and mathematical analysis of text.
187103	192567	He basically learned to write things that could figure out whether an email was in order or not.
193712	199755	I took on a nights and weekends project at Kickstarter where I was like, we're getting all these incoming projects and most of them are good.
199755	206098	And, you know, we're trying to, in the early days, decide which ones were a Kickstarter project and which ones weren't a Kickstarter project.
206098	207578	And they took this very seriously.
207578	209279	It was like, it has to be a creative project.
209279	212060	You can't raise money for your vacation.
212060	213381	It has to be for a documentary.
213381	215542	So people would come up with funny ways to do that.
215922	223244	Fred had a hobby project besides his work where he tried to make an artificial intelligence that could scan the many.
223244	233547	Suddenly Kickstarter became big and very popular and they had to find a way to automatically find out which projects were probably Kickstarter projects and which were to be chosen.
233547	236928	So I had a friend who worked at Y Combinator and he said, well,
237668	244570	We're interested in doing something similar with it with an algorithm so that it looks at incoming people who are applying to Y Combinator Would you be interested in working on that?
244570	258133	I was like, yeah, I mean I was always interested in living in California So I took them up on it and I moved out there and that was in 2016 So I worked a little bit on that but then I ended up kind of being part of the whole Y Combinator process and meeting there and that's how I met Sam Altman
258647	260609	Yeah, that was just my clue.
260609	261930	Let's talk about Sam Altman.
261930	262230	Sure.
262230	266353	Your first meet-up with Sam Altman, what was that?
266353	270957	You know, he interviewed me when I was applying for the job at YC.
270957	278042	And I remember we were in a tiny room and he was rolling around on one of those hoverboards.
278042	278583	Do you remember those?
278583	279423	A hoverboard?
279423	280924	It's not an actual hoverboard.
280924	282105	It's the one with the wheels.
282105	282385	Okay.
282385	285248	It was just very funny to be doing an interview while he was going around the room.
285828	286429	I was impressed.
286429	290513	I mean, I thought he, um, you know, we just, we stayed friendly while I worked there.
290513	303907	And, um, I saw him do what Henrik was talking about, which is get people to think bigger because that's, that's the risk with a startup is if you don't think big enough, then suddenly you're just talking about sleeping on couches instead of the hotel industry.
303907	304127	Right.
304127	305729	Which is a lot bigger than sleeping on couches.
306269	316497	And so that was kind of my first impression was like his skill was getting people to think creatively about how big a vision could be and kind of coaxing them to that point.
316497	330269	So Fred's first meeting with Sam Altman is in 2016 for his job interview, where Sam Altman meets up on one of these electric skateboards, hoverboards, where he drives around in the room while they're having this job interview.
330269	334112	What catches Fred in the same way is that he is incredibly good at thinking big
334753	337085	Try to describe him as a person.
337085	337890	What kind of person is he?
338587	346713	You could tell he was interested in kind of the abstract big ideas and maybe not as interested in the kind of day-to-day.
346713	349856	A little bit like Steve Jobs, kind of.
349856	350336	Possibly.
350336	352878	I've never met Steve Jobs.
352878	353479	I've heard about him.
353479	354199	I've read a book or two.
354199	358623	But yeah, I mean, I think he was thinking as big as it could be.
358623	365148	And I think AI was particularly interesting for that reason, because around that time, within a couple of years,
366649	369550	it looked within sight to do something really big with AI.
369550	370891	And I think that's what attracted him.
370891	376713	And it wasn't surprising for me to hear that he was shifting to open AI after YC.
376713	385176	I'd say Sam is up there with Mark Zuckerberg, Elon Musk, Sundar Pichai from Google, the biggest tech bosses in the world.
385176	389398	If you had to compare him to, say, Zuckerberg, how do they differ?
389398	392279	I mean, I've only met Zuckerberg once.
392279	394239	And he was perfectly nice to me.
394239	395420	But I don't think we got along as
396975	400677	as well as I, for whatever reason, as well as I got along with Sam.
400677	407780	And I think Sam seems acutely interested in listening to the concerns people have.
407780	417024	I mean, if your audience is kind of interested in reading more, he did a great interview with Ezra Klein of the New York Times, which I think is worth listening to or reading.
417724	421729	And you can see him and Ezra going back and forth on like some of these big picture concerns.
421729	426634	And, you know, he had some of these comments in Congress about, OK, well, maybe you're right.
426634	428516	Maybe this is concerning or this is concerning.
428516	430758	And I think I think those are are genuine.
430758	432320	I also think it's
432620	437863	in OpenAI's interest now to kind of ask some of those questions now that they've ended up dominant.
437863	442365	So he's also very smart and knows how to play chess really well, both literally and figuratively.
442365	452449	Fred fortæller at Sam Altman, måske virkeligen adskiller sig mest for de andre tech-chefer ved at han faktisk bekymrer sig om hvad folk vil ha, hvad folk tænker.
452449	459793	Han mødte for nylig opp i kongressen i en høring om truslen for kunstig intelligens, og sagde jo at han mente at der var klare problemer
460654	467419	OpenAI, the folks behind ChatGPT, kicked off as non-profit, aiming to make friendly AI that helps everyone.
467419	470321	They didn't just want Google and Facebook to have all the fun with AI.
484630	498373	And later they shifted gears and went for what they call for-profit or capped profit, which means that there's kind of a lead to how much cash the investors can make and anything extra goes back to the organization's original purpose.
498373	508876	And OpenAI says they made the switch because they needed it for server capacity, high priced research, stuff like that to train those large language models.
508876	514337	Doesn't that just prove that at the end of the day, no matter how noble the cause, it's all about the money?
515778	518179	I mean, I think that's putting too fine a point on it.
518179	529285	I mean, if you look at how much it actually cost to get OpenAI to where they are right now relative to that, it's actually a little bit on the smaller side.
529285	531046	I mean, it's billions of dollars probably.
531046	535088	I mean, I think they took over $10 billion from Microsoft.
535088	541071	But it's a little bit unclear where it's all going to shake out in terms of actual profit.
541071	544153	I think something that Sam talks a lot about that I'm skeptical of is,
544693	547734	is this will just obviously generate wealth in the future.
547734	549454	And I'm not sure about that.
549454	556395	I think it's an interesting tool and I've been enjoying using it and I think it portends really interesting things for the future in technology.
556395	564557	But the idea that it's just going to generate outsized profits and money is like, the jury is still out on that one for me.
564557	569898	So I think there's a lot of interest and there's a lot of belief that it will generate huge amounts of money, but we'll see.
570729	591393	OpenAI started as a non-profit, a company that couldn't make money, and when it became clear to them that it was expensive to train these models, to attract the right scientists and employees, and to make Microsoft knock on the door with a lot of money, then OpenAI changed, which among other things was financed by Elon Musk and others, to be for-profit, but with a profit-loft.
591833	601919	And Fred asks himself if any of the ideas Sam Altman has about how extremely profitable AI is and transformative for society, if they will actually happen.
603118	609621	In Silicon Valley, they talk about the risk that we could all be finished all because of AI.
609621	614623	They contemplate the end of humanity, and they call it P-Doom.
614623	615963	The probability of doom.
615963	617324	Exactly.
617324	621866	Fred, as a person who I assume dine and chat with people in Silicon Valley,
622546	625129	Can you describe the vibe right now?
625129	628292	Are people anxious, optimistic?
628292	629073	How is it?
629073	639584	Well, I think there's a risk for the folks who are saying the sky is falling because it's kind of hard to prove one way or another.
639584	640425	Where it's not happening.
640425	644829	Yeah, it's like if it's not happening now, I mean, so we have to like project and look into the future and kind of
645650	646511	figure that out.
646511	654576	And I think there's a lot of incentive for people to say, hey, you guys aren't thinking enough about this.
654576	660760	And like, pay attention to me, because then they get to kind of ride on the coattails of the AI conversation by just saying the opposite.
660760	664923	So it's a, you kind of have to like figure out like, okay, how likely is this?
664923	667905	And you have to look at the technology and you have to look at how people are actually using it.
668505	674787	And right now, for the better, everyone is using AI with a human in the loop.
674787	679729	And I think that's a good phrase for your audience to understand and kind of process.
679729	684851	And what that means is that when I sit down to use ChatGPT, I am directing ChatGPT.
684851	689853	I'm saying, hey, help me write this code, or reformat this email, or whatever.
689853	695795	We're not at the point where we're just letting AI be an agent in the world with its own motivations and its own desires.
696355	699259	And I think that's actually where things could go awry.
699259	704925	I, having worked with a lot of AI systems, more often than not, they just make, like, dumb decisions.
704925	708909	They're not, you know, not necessarily, like, malicious.
708909	716798	And it's hard, like, for me to imagine, just with my experience of it going from a stupid or bad decision to a malicious decision.
717418	729648	And I think, you know, this is where alignment, the conversation around alignment, which is this kind of code word in the AI world of, does the AI's motivation align with the human's motivation?
729648	736773	And this goes all the way back to science fiction from the 50s and 60s around, will the robots always listen to us?
736773	741076	And I think OpenAI, to their credit, has spent a lot of time making sure that they like,
741977	745400	factor this into the way that they're building AI.
745400	747482	And there are a lot of smart people thinking about it.
747482	752367	Honestly, to answer your question about the vibe, I think a lot of people are really kind of bothered by the Doomers.
752367	757111	And they're just kind of... What do you mean, bothered by the Doomers?
757111	758692	I think some of them
759553	768699	some of the demands from the people who think that AI doom is coming and some of the projections about what we should do in that event get a little wonky.
768699	773463	There was somebody I think I saw advocating for bombing data centers.
773463	774043	Oh my god.
774043	774323	Yeah.
774323	776164	Is that a movement?
776164	779587	It's not a movement, but it was like a somewhat serious suggestion.
779587	780207	Okay.
780207	781228	In order to kind of
781788	785151	stave off the incoming AI apocalypse.
785151	793998	And it was kind of somewhat seriously suggested as a way that humans could defend themselves against the future.
795207	797328	I think stuff like that hurts the credibility.
797328	798908	I think there are risks around AI.
798908	800329	I'm not pretending there aren't risks.
800329	806271	I think talking about it in a hyperbolic Doomer sense doesn't move the conversation forward.
813753	827958	And Fred says that the mood in his circle is that you are a little tired of these people who think the sky falls down on their ears, and there are some completely crazy proposals where people, for example, say that you should bomb a data center to stop the development.
829678	839122	So Fred, these doomers have this naive idea.
839122	841923	What are the deeper and more real threats you see?
841923	847125	And I think you're quite aligned with Sam Altman, actually, from our conversation, so I will use you as a sort of...
847986	864784	amalgamate of the two of you well obviously I can't I can't speak for Sam on this stuff but having confronted AI systems going awry and working well one of the big things that everyone talks about this is not gonna be surprising is bias and I think open AI has done a lot of work to try to
865424	868125	make sure that the system is basically unoffensive.
868125	875569	And what's interesting is the narrative around AI has kind of shifted from, oh, what happens if these algorithms are racist?
875569	878410	Like, people aren't talking about that very much right now.
878410	882132	And it's because the main algorithm that everyone's working with isn't racist.
882132	883833	It's actually quite hard to get it to behave.
884733	887034	in a anti-social way in that sense.
887034	895796	That doesn't mean the training data and the way that the model works under the hood didn't kind of absorb all of the racism and bad things in society.
895796	896336	It did.
896336	900917	It's just that open AI has put kind of a layer on top of it to make it safe.
900917	903818	And there's a lot of people experimenting with these larger language models now.
904698	910462	an open source one from Facebook, and the way that they get released is very conservative.
910462	918368	You can ask it to make a joke about a panda, and it'll be like, well, you shouldn't because pandas are endangered.
918368	926814	So people are paying attention to those concerns, and I think it's because of journalists and activists saying, well, we've got to make sure bias isn't a problem.
927034	930537	One of the first concerns is that the AI systems have built in bias.
930537	933379	He says that OpenAI and others have actually been really good.
933379	935020	It's not something we discuss so much.
935020	941005	We saw earlier examples of how these language models very quickly ended up being racist or asocial.
941005	945868	That has been managed to prevent, at least with this very cautious release cycle.
945868	951773	That is, you do not release any language models that fall into that hole, which is a clear risk that they have bias.
953121	956203	What is your P-Doom?
956203	959945	My likelihood of doom given AI?
959945	964469	Oh man, it's so hard to predict the future in general.
964469	965389	Just give us a number, Fred.
966776	967176	I don't know.
967176	971158	I'd say between 5% and 10% there's actual harm.
971158	980082	Not like human civilization has gone wrong, but something at the top of society has gone off the rails in 20 years.
980082	981262	I'd say 5% to 10%.
981262	983163	We're not going to go extinct.
983163	985444	We're going to go extinct based on our own hand.
985444	987305	It's not going to be the machines hit to it.
987605	999232	Then the question is how far we are exposed by artificial intelligence and the real percentage says that he actually thinks that there is a 5-10% risk that something in society goes seriously wrong within 20 years.
999232	1006277	Maybe not that we are exposed, but we have to take care of it ourselves, but that there is something else at a high level in society that breaks down altogether because of artificial intelligence.
1006756	1008058	I don't like that.
1008058	1010100	I mean, listen, it's a trade off, right?
1010100	1018208	Like I'm reading the Oppenheimer biography and I watch the movie and that technology was designed only to cause destruction, right?
1029420	1042695	And it's a comparison that occurs a lot in this circle with that you developed a technology that was only to be used for death and destruction, and you are afraid that Artificial Intelligence is also on the way in that direction.
1043735	1050759	So I think there's this kind of impulse to build something really powerful and that's where the two projects are kind of similar.
1050759	1057282	And then you look back and you say, wow, did we unleash something terrible and is it going to destroy society?
1057282	1063365	And I mean, nuclear energy has some of the possibility of saving society, right?
1063365	1064426	I'm a big proponent of
1065707	1071655	nuclear fusion power plants and what they could mean for sustainable energy.
1071655	1077563	But obviously they cause a huge amount of destruction in Japan and that's a serious consequence.
1077563	1080446	And we live with the threat of nuclear war.
1080446	1081428	I mean, it's just a part of
1081888	1082589	our society now.
1082589	1084792	So, you know, Marcel saying, oh, I don't like that.
1084792	1091179	I'm like, well, I don't like the fact that, you know, America has thousands of nuclear warheads just ready to go all the time.
1091179	1094763	And technology isn't unambiguously good, you know?
1094763	1101691	And I think that that's something that we've had to learn as all of the world has come online and these systems have become more powerful.
1102166	1109772	The comparison with Oppenheimer and nuclear power is good because we have seen that nuclear technology plays an important role.
1109772	1113535	It is in many ways a good energy source.
1113535	1118418	Phat says that he is a big supporter of fusion energy, which has some incredibly positive results.
1119779	1123902	We read an interview yesterday, back from 2016.
1138893	1142835	And that's seriously frightening, but in a way also funny.
1142835	1156904	Altman says, I try not to think too much about it, but I have guns, gold, potassium, iodide, antibiotics, batteries, water, gas mask from Israeli Defense Force and a big patch of land in Big Sur I can fly to.
1158705	1160046	It really spooks me.
1160046	1165749	Yeah, I mean, the CEO of OpenAI says this.
1165749	1166730	I got it.
1166730	1181498	I mean, I think the instinct to prep for the future is maybe best thought of as independent from the technology that they're creating, because it's actually just a kind of engineering approach to the world.
1181498	1183059	When you build complicated systems,
1183859	1188360	You can get 80% of the way there with a straightforward design.
1188360	1191561	But when things break, it's on the edges.
1191561	1193382	It's outlier situations.
1193382	1203424	And good engineers, people who, whether it's they're thinking about the future or millions of users, they're planning for these kind of outside possibilities happening.
1203424	1205005	But is he serious saying this?
1205005	1206505	Or is it kind of a joke?
1206505	1207706	No, I believe he has that.
1207706	1209106	I think he's being totally sincere.
1209106	1211967	So the question is, is he linking
1213067	1218228	the technology that he's working on to the idea that he needs to prep for the apocalypse.
1218228	1222529	No, I think it's just a general kind of paranoia around what's going to happen in the future.
1234412	1240941	And it's very typical for these nerds that they like to prepare for all scenarios and solve problems themselves.
1240941	1243925	And that's not necessarily tied to artificial intelligence.
1244873	1248056	And let's just aim for a hopeful finish here.
1248056	1254342	Make me a believer and convince me that I don't have to brace for Armageddon.
1254342	1258787	But we're heading into a bright future with AI.
1258787	1260749	I can't help you with the doom, man.
1260749	1264492	Not the doom, but the realistic scenario, the optimistic scenario.
1264492	1264993	What would that be?
1266206	1278774	Well, I think it's that we continue to have humans in the loop kind of harnessing the best parts of AI and the AI is ultimately subservient to us.
1278774	1280155	And I think that's possible.
1280155	1283237	I mean, everyone who's building those systems is thinking in those terms.
1283237	1295545	I don't think there's a kind of villainous, I mean, who knows what China's doing, but like, I don't think there's a villainous CEO out there who just wants to delegate everything to the AI and make sure it has, you know, its own motivations and that kind of thing.
1296025	1307857	So the one silver lining of the companies being concentrated or the power being concentrated in these companies is that there's only really a handful of them to regulate and they have the power.
1307857	1318488	And so if OpenAI or Microsoft or Facebook, if we put pressure on them to do the right thing, set up the best practices, hopefully the fact that it's concentrated means that we can control it more.
1318948	1325853	Fred's optimism about the future of AI can best be exemplified by how he works with it himself.
1325853	1336641	He has a small company where he spreads customer service, he develops the product, he does everything himself, and there he uses chatGBT to delegate work tasks so he can do this and make a deal on a crazy idea.
1338002	1338682	Perfect.
1338682	1339343	That was really fun.
1365417	1368698	Fred Benenson, thank you so much for taking time talking to us.
1368698	1371220	I've heard you were going for, what, Louisiana?
1371220	1372720	Well, not the state, but the museum.
1372720	1374341	Yeah.
1374341	1376382	He's going to take the Tesla now and disappear.
1376382	1377562	Oh, he's going to take your Tesla.
1377562	1378763	Yeah, it's a good deal.
1387497	1396361	What does your wife say about you having a living husband?
1396361	1398322	That's off-topic, Marcel.
1399772	1413348	Henrik, we have come to Apple Podcast and Spotify, and we must of course say that we are also in DL Lyd, but more interestingly, we have also received our first application in Apple Podcast.
1413348	1416031	Yes, there is one that has given us one star.
1418113	1419934	It's just to understand.
1419934	1422955	I've heard it and I think it was... I'm sure it was him who thought you spoke too much English.
1422955	1423515	Yes, I think so too.
1423515	1424895	But I think it's fair enough.
1424895	1427996	He thinks it's a bad show because of that.
1427996	1430837	But I want to read a little bit from our first review.
1430837	1432978	It's written by a person called...
1433818	1434779	Molgatti.
1434779	1440463	It sounds a bit like a CIA attack from the 70s or a legendary mortadella chef.
1440463	1450630	We get five stars and the host writes, I apologize, but I do not have specific information about the DR podcast promptly, as my knowledge goes until September 2021.
1450630	1458035	I think maybe you should read it properly, Marcel, because it says, as an A-language model, I cannot evaluate this podcast.
1458435	1465201	And then it says in the text, I'm sorry, but I don't have specific information about this podcast, as my knowledge only goes as far as September 2021.
1465201	1471767	It is possible that it is a newer podcast or one that has not gained widespread attention within this time frame.
1471767	1476772	I recommend checking their official website or other reliable sources for more detailed and updated information about this podcast.
1477032	1482597	Why did you write a review of our show with these ads?
1482597	1500170	It was actually a practical joke a few hours later, because I saw that we had come up, and then I wanted to see if Apple would accept if you used the chat GPT to review it, so I wrote a prompt to chat GPT, evaluate, review, evaluate this podcast, and then I got this answer, and then I actually wrote the headline myself, because
1501352	1516730	It's a meme, a thing that people have fun about on the internet for a long time, that people who have used ChatGPT sometimes forget to remove a sentence that in English reads, as an AI language model, I cannot, and then it explains why it can't answer a question.
1516730	1520474	And there are a lot of people who have found examples of this in everything from
1521335	1528119	I mean, some user references, for example, like podcasts, but also on Amazon and on Yelp in the USA.
1528119	1530501	I have also found it on some Danish websites.
1530501	1539927	And it has become such a thing that you can find on Twitter, where some bots write false tweets, often where they look a lot like dressed women.
1539927	1541888	It has become such a whole thing to find them.
1541888	1549113	I mean, specialized scientific articles have this sentence in them, and it is a way of how you can see
1549673	1552694	that chat GPT has been used and therefore does not want to answer the questions.
1552694	1560478	But it's super interesting that we are on our way to an internet that is read with all this AI generated crap.
1560478	1562979	Reviews are a pretty important resource in a way.
1562979	1565560	It is in the way that we as consumers orient ourselves around.
1565560	1570422	What is there to say about this product, apart from what they themselves write to the producer, right?
1570422	1573023	And the credibility that is in the reviews, it is about to be destroyed in a way.
1573023	1574204	I mean, it's probably broken.
1574204	1575785	It has been destroyed for a long time, Marcel.
1575785	1576345	I'm sorry to say it.
1576645	1579266	But what's the purpose of all these posts?
1579266	1582326	Except for yours, of course, which was the Troll-app.
1582326	1584727	But what's the purpose of all these fake posts?
1584727	1587887	Well, I found, for example, a website that was kind of a link-farm.
1587887	1593689	Those were the old days, where you put a lot of text on a page that was about something to get traffic in, and then you served some ads.
1593689	1594229	Can I see it?
1594229	1595989	Yes, let me find it here.
1595989	1596289	Yes.
1596289	1598970	It's called tv- og internet.dk.
1598970	1602911	All you need to know about Danish homepages, TV and Internet packages.
1602911	1604551	Can I see it?
1604551	1605071	It comes here.
1605883	1611024	And I found that by googling the sentence as an AI-language model.
1611024	1611944	Yes.
1611944	1616865	There's a picture of a remote control, and then there's pretty much everything you need to know about TV and the Internet.
1616865	1627967	And it has a whole bunch of sub-pages about TV and the Internet in Fjerretslev, TV and the Internet in Brabrand, TV... I mean, for every location in Denmark, they've just automated and made a whole bunch of sub-pages.
1627967	1633508	So when someone wants to find an Internet connection in their local area, they can go to this page here.
1634108	1639449	And then there's a whole bunch of text that apparently seems reasonable, but is completely ridiculous.
1639449	1643070	The homepage now has a sub-section called, How do Danish homepages work?
1643070	1650912	And then it starts, As an AI language model, I can tell that Danish homepages work in Danish by using Danish as the primary language on the website.
1650912	1655913	This includes everything from navigation menus, transcripts, spreadsheets and buttons to contact forms and payment processes.
1655913	1663075	In addition, Danish homepages often adapt the Danish culture and ways of trading, for example, with the typical Danish currency as standard currency, and then it just continues.
1663975	1666218	It's a robot home page.
1666218	1669020	And then I looked at an even more local home page.
1669020	1680772	It said, for example, technology that is able to send Wi-Fi signals directly to devices, that this is an alternative to signals in your society of a placeholder, that means that the unit you run water on Netflix.
1681593	1682334	It really became black.
1682334	1683376	It's pretty black, yes.
1683376	1684137	I understand that.
1684137	1690346	And I think it's just a combination of having machine-translated, ungenerated text, and not checking it afterwards at all.
1690346	1694372	It's fascinating that we're on our way to a robot world, where robots are reading the robot's home.
1696595	1698376	And the robot is listening to the robot's music.
1698376	1709745	This is a robot that is trying to create a website that will appear on top of the Google search results, so that you have to go in and click on a link to set up an internet connection at Nordlys, or Stofa, or QuickNet.
1709745	1713388	And then there's a man in a teenager's MV making money on me clicking on that link.
1713388	1718992	And then they get a kickback, a small receipt for every time someone signs up for an internet connection.
1720248	1726952	How can it be that it is so difficult to discover if something is written by an AI or a human?
1726952	1734596	It is of course the dilemma that school teachers and university researchers sit with when they get these assignments written by ChatGPT at the door.
1734596	1742541	It may be easy to get an idea that it is written by ChatGPT, but it is partly difficult to prove that it actually is.
1742541	1744382	It's not plagiarism control in that way.
1744382	1746463	There was also a story before.
1747283	1756906	The Verge among others, and a lot of other media, about how OpenAI was developing a tool to detect what is made by a human, what is made by a robot.
1756906	1761008	But they have, without making a big deal out of it, in silence, shut down this tool.
1761008	1764349	And the reason was simply too low precision.
1764349	1765729	The tool was simply too bad.
1765729	1767910	It could not distinguish between text made by humans and AI.
1768750	1772611	Why is it technically so difficult to make this tool?
1772611	1780114	Well, what a chatbot does is that it basically searches for what it has read in a whole bunch of texts that it has been served as training data.
1780114	1790217	That means that it will statistically go out from some calculations it has made every time, what is the most likely answer to this question, and therefore it will often generate unique content.
1790217	1797040	The less you ask about something very specific that it has very little data to answer from, the more you will get different answers every time.
1797660	1809705	And the reason why you can use this sentence as an ES-model, is that it's only when it doesn't want to answer for some reason, for example ethical or other reasons, that it gives this recognizable sentence.
1809705	1811445	And it doesn't do that all the time.
1811445	1816247	So therefore, it will be a different text you get every time, and it dictates, it finds everything.
1816247	1821129	There's a researcher who has called generative AI bullshit machines.
1821129	1823430	They can talk and let the background go.
1824410	1834937	But they don't really know what they're saying, and that's why it's very difficult to detect, because they're so good at making it sound very, very real, but it never is.
1834937	1835557	Does that make sense?
1835557	1836418	Yes, it makes sense.
1836418	1848285	It reminds me a bit of if you were to have a job interview with someone who just comes in and likes a whole bunch of bullshit, then you would expose the applicant for some tests, maybe, or something like that, which could reveal that this is bullshit.
1851427	1854751	And that's exactly what OpenAI has done with this Classifier tool.
1854751	1858675	They have taken some texts that they knew were written by ChatGPT.
1858675	1860737	They have taken some texts that they didn't know were.
1860737	1862940	And I think it was 29% of the time they could detect
1868285	1872686	when it was generated, it was simply too bad for bad results.
1872686	1874987	And therefore they have chosen to postpone the project.
1874987	1876408	And I think that's actually very sensible.
1876408	1891852	Yes, of course, there is nothing wrong with that decision, but it is more that it is perhaps quite worrying that the company that is far ahead, perhaps, with generative AI right now, cannot develop a tool that can reveal whether what this robot has done is generated by AI or not.
1891852	1893173	So it's pretty scary in a way.
1893173	1895113	Yes, and interesting too.
1895113	1896694	How much of your racing cycles actually
1899588	1904329	I haven't bought new ones recently, so I can't deliver any very, very high rates.
1904329	1904950	Okay.
1904950	1906310	What about Tesla?
1906310	1907650	I've leased it myself.
1907650	1909951	You won't get me this time.
1909951	1917633	Well, I can inform you that FTC, the Federal Trade Commission of the United States, will shut down what they call dishonest reporting practices.
1918653	1921654	For example, false reports can also be read about on The Verge.
1921654	1929077	FTC mentions the specific origin of AI chatbots as something that makes it easier to make false reports.
1929077	1931458	And the payment size can go up to $50,000.
1931458	1933759	That's a little more than my bike.
1933759	1935520	Yes, but not more than your monthly salary.
1935520	1935860	Yes, it is.
1936200	1946003	But I think it's going to have a devastating effect, because it's actually the case that applications, also here in Denmark, but to an even greater extent in the USA, have been completely impossible to trust for a very, very long time.
1946003	1948884	I mean, what you call organic applications, i.e.
1948884	1954286	applications that have been written by real people who are honest, have been largely useless for a long time.
1954286	1956507	I'm looking forward to seeing if you get a ticket for this.
1956507	1958667	I'll be happy if it happens.
1958667	1959988	We like real applications.
1960990	1969054	So if you like the show, go to Spotify or Apple Podcasts and give us a like for every one you get.
1969054	1971736	That was episode 2 of Prompt.
1971736	1972976	I think you did a great job, Henrik.
1972976	1974277	You're very much like me.
1974277	1974937	At least I got smarter.
1974937	1977739	We're coming out every Thursday on the podcast IdeaLyd.
1977739	1979299	You can listen to it from the morning show.
1979299	1987844	I was wondering if we could meet this weekend and listen to the rest of your harddisk collection.
1987844	1989525	I don't think we need that, Marcel.

**Henrik:** **Do you want me over here?

**Marcel:** **Yeah that's perfect. **Nice to meet you, Fred. **Very nice to meet you. **Thank you for being here.

**Fred:** **Thanks for having me.

**Marcel:** **Henrik, can you just start, give us a very short round, how do you and Fred know each other?

**Henrik:** **So Fred and I have been friends and worked together briefly back in 2006-7. **I was working on a documentary about copyright. **Fred was working at a non-profit called Creative Commons, the licensing system that underpins things like Wikipedia. **And so we were in this **group of people that were very idealistic about the internet, and have stayed friends ever since.

**Marcel:** **That's perfect. **And you've been hanging around in Copenhagen for a couple of days?

**Fred:** **Yeah, I got here a week ago, I guess. **And then I went to Sweden for a bit, but Henrik's given me an incredible tour. **We went mushroom hunting on Friday, and that was amazing. **And then I'm going to... In which forest was that?

**Marcel:** **Sysvile.

**Fred:** **Sysvile, yeah. **Yeah, it was wonderful. **We got lots of chanterelles, but what was the Danish name for them? **Cantareller. **Cantareller, yeah. **They were amazing. **We cooked them that night. **Are they good? **Yeah, they were great.

**Marcel:** **Ah, okay, perfect. **And do you sleep on Henrik's sofa?

**Fred:** **No, he's got an incredible guest room. **It was a lovely, it's been a lovely stay.

**Henrik:** **Som Fred fortæller her, så er han i København for at besøge mig. **Vi er gamle venner. **Vi har været ude og samlet svampe. **Og han bor i mit gæsteverelse i vores hus.

**Marcel:** **Enough with the hygge and Denmark, you've worked with artificial intelligence for so many years, first at Kickstarter, then at Y Combinator, we'll get back to that in a minute. **What were you trying to accomplish with AI within your career?

**Fred:** **So I took a really interesting class in grad school by somebody named Dan Schiffman, courseware, he's a great teacher, and I think the class he taught was called Nature of Code. **and then programming A to Z, and he showed us how to build a spam filter, which sounds really boring, but it's a really interesting way to analyze large amounts of text.

**Marcel:** **So the spam filters we have in our Gmail, which means I don't have to look up hundreds of mails that I don't want to see. **Exactly.

**Fred:** **It's a powerful mathematical algorithm that goes back to probability theory that can analyze an email really quickly and say, it's more likely than not that this email is spam. **So I learned how to do some of that math. **And a couple of years later, I found myself at Kickstarter. **I was the second employee there, and just trying to make myself useful at a startup. **take on interesting projects, and do everything from look at our analytics, to answer queries from the database, to build a little bit of code. **And I picked up a, in America, they called it nights and weekends project. **I don't know if that's a phrase here. **It's probably. **No, we take the weekends off here.

**Henrik:** **I know. **It's like probably. **Yeah, we don't know that, yeah.

**Marcel:** **We have no age comps. **Yes.

**Henrik:** **Fred studied at the university and wrote code. **He was interested in, among other things, a course he took at the university, how spam filters work, and how to use algorithms and mathematical analysis of text. **He basically learned to write things that could figure out whether an email was in order or not.

**Fred:** **I took on a nights and weekends project at Kickstarter where I was like, we're getting all these incoming projects and most of them are good. **And, you know, we're trying to, in the early days, decide which ones were a Kickstarter project and which ones weren't a Kickstarter project. **And they took this very seriously. **It was like, it has to be a creative project. **You can't raise money for your vacation. **It has to be for a documentary. **So people would come up with funny ways to do that.

**Henrik:** **Fred had a hobby project besides his work where he tried to make an artificial intelligence that could scan the many. **Suddenly Kickstarter became big and very popular and they had to find a way to automatically find out which projects were probably Kickstarter projects and which were to be chosen.

**Fred:** **So I had a friend who worked at Y Combinator and he said, well, **We're interested in doing something similar with it with an algorithm so that it looks at incoming people who are applying to Y Combinator Would you be interested in working on that? **I was like, yeah, I mean I was always interested in living in California So I took them up on it and I moved out there and that was in 2016 So I worked a little bit on that but then I ended up kind of being part of the whole Y Combinator process and meeting there and that's how I met Sam Altman

**Marcel:** **Yeah, that was just my clue. **Let's talk about Sam Altman. **Sure. **Your first meet-up with Sam Altman, what was that?

**Fred:** **You know, he interviewed me when I was applying for the job at YC. **And I remember we were in a tiny room and he was rolling around on one of those hoverboards.

**Marcel:** **Do you remember those?

**Fred:** **A hoverboard? **It's not an actual hoverboard. **It's the one with the wheels. **Okay. **It was just very funny to be doing an interview while he was going around the room. **I was impressed. **I mean, I thought he, um, you know, we just, we stayed friendly while I worked there. **And, um, I saw him do what Henrik was talking about, which is get people to think bigger because that's, that's the risk with a startup is if you don't think big enough, then suddenly you're just talking about sleeping on couches instead of the hotel industry. **Right. **Which is a lot bigger than sleeping on couches. **And so that was kind of my first impression was like his skill was getting people to think creatively about how big a vision could be and kind of coaxing them to that point.

**Henrik:** **So Fred's first meeting with Sam Altman is in 2016 for his job interview, where Sam Altman meets up on one of these electric skateboards, hoverboards, where he drives around in the room while they're having this job interview. **What catches Fred in the same way is that he is incredibly good at thinking big

**Marcel:** **Try to describe him as a person. **What kind of person is he?

**Fred:** **You could tell he was interested in kind of the abstract big ideas and maybe not as interested in the kind of day-to-day.

**Marcel:** **A little bit like Steve Jobs, kind of. **Possibly.

**Fred:** **I've never met Steve Jobs. **I've heard about him. **I've read a book or two. **But yeah, I mean, I think he was thinking as big as it could be. **And I think AI was particularly interesting for that reason, because around that time, within a couple of years, **it looked within sight to do something really big with AI. **And I think that's what attracted him. **And it wasn't surprising for me to hear that he was shifting to open AI after YC.

**Marcel:** **I'd say Sam is up there with Mark Zuckerberg, Elon Musk, Sundar Pichai from Google, the biggest tech bosses in the world. **If you had to compare him to, say, Zuckerberg, how do they differ?

**Fred:** **I mean, I've only met Zuckerberg once. **And he was perfectly nice to me. **But I don't think we got along as **as well as I, for whatever reason, as well as I got along with Sam. **And I think Sam seems acutely interested in listening to the concerns people have. **I mean, if your audience is kind of interested in reading more, he did a great interview with Ezra Klein of the New York Times, which I think is worth listening to or reading. **And you can see him and Ezra going back and forth on like some of these big picture concerns. **And, you know, he had some of these comments in Congress about, OK, well, maybe you're right. **Maybe this is concerning or this is concerning. **And I think I think those are are genuine. **I also think it's **in OpenAI's interest now to kind of ask some of those questions now that they've ended up dominant. **So he's also very smart and knows how to play chess really well, both literally and figuratively.

**Henrik:** **Fred fortæller at Sam Altman, måske virkeligen adskiller sig mest for de andre tech-chefer ved at han faktisk bekymrer sig om hvad folk vil ha, hvad folk tænker. **Han mødte for nylig opp i kongressen i en høring om truslen for kunstig intelligens, og sagde jo at han mente at der var klare problemer **OpenAI, the folks behind ChatGPT, kicked off as non-profit, aiming to make friendly AI that helps everyone. **They didn't just want Google and Facebook to have all the fun with AI.

**Marcel:** **And later they shifted gears and went for what they call for-profit or capped profit, which means that there's kind of a lead to how much cash the investors can make and anything extra goes back to the organization's original purpose. **And OpenAI says they made the switch because they needed it for server capacity, high priced research, stuff like that to train those large language models. **Doesn't that just prove that at the end of the day, no matter how noble the cause, it's all about the money?

**Fred:** **I mean, I think that's putting too fine a point on it. **I mean, if you look at how much it actually cost to get OpenAI to where they are right now relative to that, it's actually a little bit on the smaller side. **I mean, it's billions of dollars probably. **I mean, I think they took over $10 billion from Microsoft. **But it's a little bit unclear where it's all going to shake out in terms of actual profit. **I think something that Sam talks a lot about that I'm skeptical of is, **is this will just obviously generate wealth in the future. **And I'm not sure about that. **I think it's an interesting tool and I've been enjoying using it and I think it portends really interesting things for the future in technology. **But the idea that it's just going to generate outsized profits and money is like, the jury is still out on that one for me. **So I think there's a lot of interest and there's a lot of belief that it will generate huge amounts of money, but we'll see.

**Henrik:** **OpenAI started as a non-profit, a company that couldn't make money, and when it became clear to them that it was expensive to train these models, to attract the right scientists and employees, and to make Microsoft knock on the door with a lot of money, then OpenAI changed, which among other things was financed by Elon Musk and others, to be for-profit, but with a profit-loft. **And Fred asks himself if any of the ideas Sam Altman has about how extremely profitable AI is and transformative for society, if they will actually happen.

**Marcel:** **In Silicon Valley, they talk about the risk that we could all be finished all because of AI. **They contemplate the end of humanity, and they call it P-Doom. **The probability of doom. **Exactly. **Fred, as a person who I assume dine and chat with people in Silicon Valley, **Can you describe the vibe right now? **Are people anxious, optimistic?

**Fred:** **How is it? **Well, I think there's a risk for the folks who are saying the sky is falling because it's kind of hard to prove one way or another.

**Marcel:** **Where it's not happening.

**Fred:** **Yeah, it's like if it's not happening now, I mean, so we have to like project and look into the future and kind of **figure that out. **And I think there's a lot of incentive for people to say, hey, you guys aren't thinking enough about this. **And like, pay attention to me, because then they get to kind of ride on the coattails of the AI conversation by just saying the opposite. **So it's a, you kind of have to like figure out like, okay, how likely is this? **And you have to look at the technology and you have to look at how people are actually using it. **And right now, for the better, everyone is using AI with a human in the loop. **And I think that's a good phrase for your audience to understand and kind of process. **And what that means is that when I sit down to use ChatGPT, I am directing ChatGPT. **I'm saying, hey, help me write this code, or reformat this email, or whatever. **We're not at the point where we're just letting AI be an agent in the world with its own motivations and its own desires. **And I think that's actually where things could go awry. **I, having worked with a lot of AI systems, more often than not, they just make, like, dumb decisions. **They're not, you know, not necessarily, like, malicious. **And it's hard, like, for me to imagine, just with my experience of it going from a stupid or bad decision to a malicious decision. **And I think, you know, this is where alignment, the conversation around alignment, which is this kind of code word in the AI world of, does the AI's motivation align with the human's motivation? **And this goes all the way back to science fiction from the 50s and 60s around, will the robots always listen to us? **And I think OpenAI, to their credit, has spent a lot of time making sure that they like, **factor this into the way that they're building AI. **And there are a lot of smart people thinking about it. **Honestly, to answer your question about the vibe, I think a lot of people are really kind of bothered by the Doomers.

**Marcel:** **And they're just kind of... What do you mean, bothered by the Doomers?

**Fred:** **I think some of them **some of the demands from the people who think that AI doom is coming and some of the projections about what we should do in that event get a little wonky. **There was somebody I think I saw advocating for bombing data centers. **Oh my god. **Yeah. **Is that a movement? **It's not a movement, but it was like a somewhat serious suggestion. **Okay. **In order to kind of **stave off the incoming AI apocalypse. **And it was kind of somewhat seriously suggested as a way that humans could defend themselves against the future. **I think stuff like that hurts the credibility. **I think there are risks around AI. **I'm not pretending there aren't risks. **I think talking about it in a hyperbolic Doomer sense doesn't move the conversation forward.

**Henrik:** **And Fred says that the mood in his circle is that you are a little tired of these people who think the sky falls down on their ears, and there are some completely crazy proposals where people, for example, say that you should bomb a data center to stop the development. **So Fred, these doomers have this naive idea. **What are the deeper and more real threats you see? **And I think you're quite aligned with Sam Altman, actually, from our conversation, so I will use you as a sort of...

**Fred:** **amalgamate of the two of you well obviously I can't I can't speak for Sam on this stuff but having confronted AI systems going awry and working well one of the big things that everyone talks about this is not gonna be surprising is bias and I think open AI has done a lot of work to try to **make sure that the system is basically unoffensive. **And what's interesting is the narrative around AI has kind of shifted from, oh, what happens if these algorithms are racist? **Like, people aren't talking about that very much right now. **And it's because the main algorithm that everyone's working with isn't racist. **It's actually quite hard to get it to behave. **in a anti-social way in that sense. **That doesn't mean the training data and the way that the model works under the hood didn't kind of absorb all of the racism and bad things in society. **It did. **It's just that open AI has put kind of a layer on top of it to make it safe.

